{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461aeb89-7546-4e17-bf48-52dd94a18fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CSV: C:\\Users\\abhin\\Downloads\\exchange_rate (2).csv\n",
      "Initial shape: (7588, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Ex_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-1990 00:00</td>\n",
       "      <td>0.7855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-01-1990 00:00</td>\n",
       "      <td>0.7818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-01-1990 00:00</td>\n",
       "      <td>0.7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-01-1990 00:00</td>\n",
       "      <td>0.7860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05-01-1990 00:00</td>\n",
       "      <td>0.7849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  Ex_rate\n",
       "0  01-01-1990 00:00   0.7855\n",
       "1  02-01-1990 00:00   0.7818\n",
       "2  03-01-1990 00:00   0.7867\n",
       "3  04-01-1990 00:00   0.7860\n",
       "4  05-01-1990 00:00   0.7849"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns detected: ['date', 'Ex_rate']\n",
      "Using date column: date\n",
      "Using series column: Ex_rate\n",
      "Warning: some dates could not be parsed (check date format).\n",
      "Frequency could not be inferred. Proceeding without explicit freq.\n",
      "Series info (head):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date\n",
       "1990-01-01    0.7855\n",
       "1990-01-02    0.7500\n",
       "1990-01-03    0.7471\n",
       "1990-01-04    0.7587\n",
       "1990-01-05    0.7852\n",
       "Name: Ex_rate, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time span: 1990-01-01 00:00:00 to 2010-12-09 00:00:00\n",
      "Frequency (inferred): None\n",
      "Missing before: 0\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Interpolation with NaNs in the index has not been implemented. Try filling those NaNs before interpolating.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 113\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# ---------- missing values handling ----------\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing before:\u001b[39m\u001b[38;5;124m\"\u001b[39m, series\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m--> 113\u001b[0m series_imputed \u001b[38;5;241m=\u001b[39m \u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mffill()\u001b[38;5;241m.\u001b[39mbfill()\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing after imputation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, series_imputed\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# ---------- basic plots & stationarity ----------\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:8498\u001b[0m, in \u001b[0;36mNDFrame.interpolate\u001b[1;34m(self, method, axis, limit, inplace, limit_direction, limit_area, downcast, **kwargs)\u001b[0m\n\u001b[0;32m   8489\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mpad_or_backfill(\n\u001b[0;32m   8490\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   8491\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8495\u001b[0m         downcast\u001b[38;5;241m=\u001b[39mdowncast,\n\u001b[0;32m   8496\u001b[0m     )\n\u001b[0;32m   8497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 8498\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mmissing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_interp_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8499\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minterpolate(\n\u001b[0;32m   8500\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   8501\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8507\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   8508\u001b[0m     )\n\u001b[0;32m   8510\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\missing.py:335\u001b[0m, in \u001b[0;36mget_interp_index\u001b[1;34m(method, index)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    328\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex column must be numeric or datetime type when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    329\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m method other than linear. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    330\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry setting a numeric or datetime index column before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterpolating.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m         )\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isna(index)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterpolation with NaNs in the index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas not been implemented. Try filling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthose NaNs before interpolating.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    339\u001b[0m     )\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Interpolation with NaNs in the index has not been implemented. Try filling those NaNs before interpolating."
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Time Series Forecasting: ARIMA & Holt-Winters\n",
    "# ===========================\n",
    "%matplotlib inline\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ---------- helper metrics / funcs ----------\n",
    "def mae(y_true, y_pred): return mean_absolute_error(y_true, y_pred)\n",
    "def rmse(y_true, y_pred): return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum()>0 else np.nan\n",
    "\n",
    "def adf_test(series, title=''):\n",
    "    print(f\"\\nADF Test: {title}\")\n",
    "    res = adfuller(series.dropna())\n",
    "    print(f\"ADF Statistic: {res[0]:.4f}, p-value: {res[1]:.4f}\")\n",
    "    print(\"Critical values:\")\n",
    "    for k,v in res[4].items():\n",
    "        print(f\" {k}: {v:.4f}\")\n",
    "    return res\n",
    "\n",
    "def train_test_split_ts(series, test_periods):\n",
    "    train = series.iloc[:-test_periods]\n",
    "    test  = series.iloc[-test_periods:]\n",
    "    return train, test\n",
    "\n",
    "def plot_series(train, test=None, pred=None, title=\"Time Series\", xlabel='Date', ylabel='Value'):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(train.index, train.values, label='Train')\n",
    "    if test is not None:\n",
    "        plt.plot(test.index, test.values, label='Test', color='orange')\n",
    "    if pred is not None:\n",
    "        plt.plot(pred.index, pred.values, label='Predicted', color='green')\n",
    "    plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)\n",
    "    plt.legend(); plt.show()\n",
    "\n",
    "# ---------- USER PATH (your path plugged in) ----------\n",
    "DATA_PATH = r\"C:\\Users\\abhin\\Downloads\\exchange_rate (2).csv\"\n",
    "FALLBACK = r\"/mnt/data/exchange_rate (2).csv\"   # environment fallback\n",
    "\n",
    "# ---------- LOAD DATA ----------\n",
    "if os.path.exists(DATA_PATH):\n",
    "    path = DATA_PATH\n",
    "elif os.path.exists(FALLBACK):\n",
    "    path = FALLBACK\n",
    "else:\n",
    "    raise FileNotFoundError(f\"File not found. Update DATA_PATH. Tried:\\n{DATA_PATH}\\n{FALLBACK}\")\n",
    "\n",
    "# read CSV (or Excel fallback)\n",
    "try:\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Loaded CSV:\", path)\n",
    "except Exception:\n",
    "    df = pd.read_excel(path)\n",
    "    print(\"Loaded Excel:\", path)\n",
    "\n",
    "print(\"Initial shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# ---------- auto-detect date and series column ----------\n",
    "cols = df.columns.tolist()\n",
    "print(\"Columns detected:\", cols)\n",
    "date_col = cols[0]\n",
    "if len(cols) >= 2:\n",
    "    series_col = cols[1]\n",
    "else:\n",
    "    raise ValueError(\"Dataset must have at least two columns: date and one series column.\")\n",
    "\n",
    "print(\"Using date column:\", date_col)\n",
    "print(\"Using series column:\", series_col)\n",
    "\n",
    "# ---------- parse date and set index ----------\n",
    "df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "if df[date_col].isnull().any():\n",
    "    print(\"Warning: some dates could not be parsed (check date format).\")\n",
    "df = df.set_index(date_col).sort_index()\n",
    "\n",
    "series = pd.to_numeric(df[series_col], errors='coerce')\n",
    "# try infer freq; if not, leave NaT and use daily freq as fallback\n",
    "inferred = pd.infer_freq(series.index)\n",
    "if inferred is None:\n",
    "    # don't force freq, but we can set daily to allow asfreq if needed\n",
    "    print(\"Frequency could not be inferred. Proceeding without explicit freq.\")\n",
    "else:\n",
    "    series = series.asfreq(inferred)\n",
    "\n",
    "print(\"Series info (head):\")\n",
    "display(series.head())\n",
    "print(\"Time span:\", series.index.min(), \"to\", series.index.max())\n",
    "print(\"Frequency (inferred):\", inferred)\n",
    "\n",
    "# ---------- missing values handling ----------\n",
    "print(\"Missing before:\", series.isnull().sum())\n",
    "series_imputed = series.copy().interpolate(method='time').ffill().bfill()\n",
    "print(\"Missing after imputation:\", series_imputed.isnull().sum())\n",
    "\n",
    "# ---------- basic plots & stationarity ----------\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(series_imputed); plt.title(f\"Series: {series_col}\"); plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(series_imputed.rolling(window=12).mean(), label='Rolling mean (12)')\n",
    "plt.plot(series_imputed.rolling(window=12).std(), label='Rolling std (12)')\n",
    "plt.legend(); plt.title(\"Rolling stats\"); plt.show()\n",
    "\n",
    "adf_res = adf_test(series_imputed, title=series_col)\n",
    "\n",
    "# ACF / PACF plots\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "plot_acf(series_imputed.dropna(), lags=40, ax=ax[0])\n",
    "plot_pacf(series_imputed.dropna(), lags=40, ax=ax[1])\n",
    "plt.show()\n",
    "\n",
    "# ---------- train-test split ----------\n",
    "test_periods = 24\n",
    "if test_periods >= len(series_imputed):\n",
    "    test_periods = max(1, int(len(series_imputed) * 0.2))\n",
    "print(\"Using test_periods =\", test_periods)\n",
    "train, test = train_test_split_ts(series_imputed, test_periods)\n",
    "plot_series(train, test, title=f\"{series_col} â€” Train/Test split\")\n",
    "\n",
    "# ---------- choose ARIMA order ----------\n",
    "use_auto = False\n",
    "try:\n",
    "    import pmdarima as pm\n",
    "    use_auto = True\n",
    "except Exception:\n",
    "    use_auto = False\n",
    "\n",
    "if use_auto:\n",
    "    auto = pm.auto_arima(train.dropna(), seasonal=False, stepwise=True, suppress_warnings=True,\n",
    "                         error_action='ignore', max_p=5, max_q=5, max_d=2)\n",
    "    print(\"auto_arima suggestion:\", auto.order)\n",
    "    p,d,q = auto.order\n",
    "else:\n",
    "    # quick AIC grid search with small ranges\n",
    "    best_aic = np.inf\n",
    "    best_order = (0,0,0)\n",
    "    # d guess by ADF\n",
    "    d_guess = 0 if adf_res[1] < 0.05 else 1\n",
    "    print(\"ADF p-value:\", adf_res[1], \"=> trying d =\", d_guess)\n",
    "    for p_try in range(0,4):\n",
    "        for q_try in range(0,4):\n",
    "            try:\n",
    "                mod = SARIMAX(train.dropna(), order=(p_try,d_guess,q_try), enforce_stationarity=False, enforce_invertibility=False)\n",
    "                res = mod.fit(disp=False)\n",
    "                if res.aic < best_aic:\n",
    "                    best_aic = res.aic\n",
    "                    best_order = (p_try,d_guess,q_try)\n",
    "            except Exception:\n",
    "                continue\n",
    "    p,d,q = best_order\n",
    "    print(\"Selected order by AIC grid search:\", (p,d,q))\n",
    "\n",
    "# ---------- fit ARIMA (SARIMAX) ----------\n",
    "print(\"Fitting SARIMAX order:\", (p,d,q))\n",
    "model_arima = SARIMAX(train, order=(p,d,q), enforce_stationarity=False, enforce_invertibility=False)\n",
    "res_arima = model_arima.fit(disp=False)\n",
    "print(res_arima.summary())\n",
    "\n",
    "# residual diagnostics\n",
    "resid = res_arima.resid\n",
    "plt.figure(figsize=(12,4)); plt.plot(resid); plt.title(\"ARIMA residuals\"); plt.show()\n",
    "res_arima.plot_diagnostics(figsize=(12,8)); plt.show()\n",
    "\n",
    "# forecast ARIMA\n",
    "n_forecast = len(test)\n",
    "arima_forecast = res_arima.get_forecast(steps=n_forecast)\n",
    "arima_mean = pd.Series(arima_forecast.predicted_mean, index=test.index)\n",
    "arima_ci = arima_forecast.conf_int()\n",
    "\n",
    "plot_series(train, test, arima_mean, title=\"ARIMA Forecast vs Actual\")\n",
    "plt.fill_between(arima_ci.index, arima_ci.iloc[:,0], arima_ci.iloc[:,1], color='gray', alpha=0.2)\n",
    "\n",
    "# ---------- Holt-Winters (Exponential Smoothing) ----------\n",
    "# try to guess seasonality from inferred freq (monthly -> 12)\n",
    "seasonal_periods = None\n",
    "if inferred and str(inferred).lower().startswith('m'):\n",
    "    seasonal_periods = 12\n",
    "elif inferred and str(inferred).lower().startswith('d'):\n",
    "    seasonal_periods = 7\n",
    "\n",
    "print(\"Seasonal periods guess:\", seasonal_periods)\n",
    "if seasonal_periods and len(train) > 2*seasonal_periods:\n",
    "    hw = ExponentialSmoothing(train, trend='add', seasonal='add', seasonal_periods=seasonal_periods)\n",
    "else:\n",
    "    hw = ExponentialSmoothing(train, trend='add', seasonal=None)\n",
    "\n",
    "res_hw = hw.fit(optimized=True)\n",
    "hw_pred = pd.Series(res_hw.forecast(n_forecast), index=test.index)\n",
    "\n",
    "plot_series(train, test, hw_pred, title=\"Holt-Winters Forecast vs Actual\")\n",
    "\n",
    "# ---------- Evaluation ----------\n",
    "print(\"\\n--- Evaluation on test set ---\")\n",
    "print(\"ARIMA Metrics:\")\n",
    "print(\"MAE:\", mae(test, arima_mean))\n",
    "print(\"RMSE:\", rmse(test, arima_mean))\n",
    "print(\"MAPE:\", mape(test, arima_mean))\n",
    "\n",
    "print(\"\\nHolt-Winters Metrics:\")\n",
    "print(\"MAE:\", mae(test, hw_pred))\n",
    "print(\"RMSE:\", rmse(test, hw_pred))\n",
    "print(\"MAPE:\", mape(test, hw_pred))\n",
    "\n",
    "# ---------- Save results ----------\n",
    "out_df = pd.DataFrame({\n",
    "    'actual': test,\n",
    "    'arima_pred': arima_mean,\n",
    "    'hw_pred': hw_pred\n",
    "})\n",
    "out_file = \"ts_forecast_results.csv\"\n",
    "out_df.to_csv(out_file, index=True)\n",
    "print(\"Saved forecast results to:\", os.path.abspath(out_file))\n",
    "\n",
    "# ---------- Notes ----------\n",
    "print(\"\\nNotes:\")\n",
    "print(\"- If pmdarima was available, auto_arima was used to suggest optimal (p,d,q).\")\n",
    "print(\"- If seasonality is known (e.g., monthly), set seasonal_periods manually.\")\n",
    "print(\"- To run SARIMA for seasonality, set seasonal_order=(P,D,Q,s) when fitting SARIMAX.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b167bfaf-6ae5-43c3-8ba3-aaff43e666a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
